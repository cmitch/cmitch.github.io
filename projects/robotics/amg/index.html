<!DOCTYPE html>
<html>
<head>

<meta charset="UTF-8">
<meta name="description" content="UC Berkeley Research into Acoustic Myography as a Valid Force Signal for Assitive Devices">
<meta name="keywords" content="CS,EE,EECS,BioE,bioengineering,robotics,amg,medical,prosthetics,exoskeletal,Berkeley,graphics,control" >
<meta name="author" content="Chris Mitchell, Eric Hu, Fayyaz Ahamed">

<link href="assets/css/main.css" rel="stylesheet" type="text/css" />

<link href="amg.css" rel="stylesheet" type="text/css" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<title>EECS 106b AMG Project</title>
</head>

<body>
<h1>EECS 106b: Acoustic Myography (AMG) as a Viable Force Signal</h1>
<h6>Chris Mitchell, Eric Hu, Fayyaz Ahamed</h6>

<h2>Project Overview</h2>
<figure>
	<table>
		<tr>
			<td>
				<img src="images/holding_egg.png" alt="Example of prosthetic holding delicate object" />
			</td>
			<td>
				<img src="images/surgery.png" alt="Example of robots assiting in surgery" />
			</td>
		</tr>
	</table>
	<figcaption>Applications of Robotics in the Biomedical Field</figcaption>
</figure>

<p>
Robotics has been slowly becoming a stable in the medical field. While electrical engineering has been present for decades with techniques such as MRI, EMG, and ultrasounds, with advancements in artificial intelligence, control theory, and grasping, more complex interactions have been made possible, allowing for assitive surgery and advanced prosthetics and exoskeletons, for example. Force is a central component to the control of these systems, as one does not wish to hurt someone or damage objects, but there exists a required amount of force to engage in these tasks. While a human can intuitively apply and adjust their exerted force amount, this problem is much more difficult for a robot to solve, and many trials would be required for a machine learning approach.
	</p>
<h3>What is AMG?</h3>
<table>
	<tr>
		<td>
<figure>
	<img src="images/horse_curo.png" alt="Use of AMG on a horse" />
	<figcaption>AMG in Use</figcaption>
</figure>
</td>
<td>
<figure>
	<img src="images/muscle_fibers.png" alt="Diagram of muscle fibers" />
	<figcaption>AMG intends to listen to the acoustic vibrations of muscle fibers</figcaption>
</figure>
</td>
</tr>
</table>

<p>
	AMG is essentially a glorified microphone, functioning like a muscle stethoscope. Just as an EMG reads in the electomagnetic waves, an AMG reads in the mechanical/acoustic waves produced by one's arm, namely by contractions. Unlike MRI's, this could work as an onboard sensor for assistive devices with minimal hinderance. Note that due to availabity of sensors, we used equine AMG sensors throughout this project.
	</p>

<h3>Goal of Project</h3>

<p>
	Prior work has suggested a mathematical relationship between the features of the AMG signal and the force the muscle is exerting. Our aim is to use this signal as a control input into a robot. From this foundation, the user could control the force a robot uses for tasks such as grasping both rigid and soft objects, compensatory force application, or indirectly controllability. For verification, we further simulated robotic grasping, using the AMG force signal as the desired contact forces.

<figure>
	<img src="images/flow_chart.png" alt="Control Flow Chart" />
	<figcaption>AMG Force Control Flow Chart</figcaption>
</figure>

<h2>Implementation</h2>

<h3>AMG Experimental Setup</h3>
<p>We performed all of our recordings using the commercially available MyoDynamik CURO (Figure 1), with the large equine AMG sensors depicted. For our recordings, we affixed a sensor to the center of the biceps, with ultrasound gel for noise insulation. Each subject was instructed to sit straight up with their elbow at a 90-degree angle, palms facing up. During the trial, subjects were told to perform isometric (motionless) contractions by pushing up against the bottom of a weighted table, using a subjective fraction of their total strength in increments of 20% for roughly 2-4 seconds, with 2-4 second rest periods in between contractions (Figure 2). We gathered a total of 25 trials from 8 subjects. All trials for any particular subject were taken back-to-back with a 1-minute rest period, without removing or replacing the sensor.</p>


<h3>Data Collection Method</h3>
<h4>Sensor Setup</h4>
<p>The AMG sensors we obtained came with the MyoDynamik CURO box, a device that allows for the sampling and recording from multiple AMG sensors. These signals are then converted into a wav file post-recording.

<figure>
	<img src="images/curobox_setup.png" alt="CURO Setup" />
	<figcaption>Original Setup Using CURO Box</figcaption>
</figure>

<p>
	While the CURO provides ease in functionality, it lacks any real-time support that we would desire for an applied system. For this reason, we also explored rerouting the signal directly from the sensor into an Arduino. After the sensor's built in amplifier, we further amplified, low pass filtered, and buffered the signal before sampling.
	</p>

<table>
	<tr>
		<td>
			<figure>
			<img src="images/circuitry.png" alt="Arduino Sensor Circuitry" />
			<figcaption>Post-Processing Circuitry</figcaption>
		</figure>
		</td>
		<td>
			<figure>
				<img src="images/arduino_sensor_setup.png" alt="Arduino Sensor Setup" />
				<figcaption>Arduino Sensor Setup</figcaption>
			</figure>
		</td>
	</tr>
</table>
<h4>Realtime versus Priorly Collected</h4>

<p>While our experiments with the real time data collection show promise, the data clearly appears cleaner with the CURO, as seen below. Note that the amplitude is irrelevant for this case as the real time did have a gain before being sampled. We suspect that the CURO does some processing that we did not do. The CURO also samples at the high rate of 1000 Hz, which would require setting changes for an Arduino to effectively replicate. For these reasons, we settled on using the CURO for our preliminary analysis.

<figure>
<table>
	<tr>
		<td>
			<img src="images/realtime_data.png" alt="Real-Time Data" class="realtimedata"/>
		</td>
		<td>
			<img src="images/curobox_sample_data.png" alt="CURO Preprocessed Data" class="realtimedata" />
		</td>
	</tr>
</table>

<figcaption>Real-Time versus CURO-Processed Data</figcaption>
</figure>

<h4>Isometric Collection</h4>
<p>For experimental design, we decided on using isometric contractions, or contractions where the arm is relatively stationary. While non-isometric results, such as with lifting a weight, could be highly informative, the onset and end of such actions creates impulses that would need to be taken into account. For this reason, we stayed with isometric experimentation by having a user apply a subjective amount of force against a table without removing their hand, measuring the mechanical output of the bicep.
<figure>
<table>
	<tr>
		<td>
			<img src="images/iso_setup.png" alt="Isometric Setup" class="isosetup" />
		</td>
		<td>
			<img src="images/nonIsoSetup.png" alt="Non-Isometric Setup" class="isosetup"/>
		</td>
	</tr>
</table>
<figcaption>Isometric versus Non-Isometric Setup</figcaption>
</figure>

<figure>
<table>
	<tr>
		<td>
			<img src="images/iso_data.png" alt="Isometric Data" class="isodata"/>
		</td>
		<td>
			<img src="images/non_iso_data.png" alt="Non-Isometric Data" class="isodata" />
		</td>
	</tr>
</table>

<figcaption>Isometric versus Non-Isometric Data</figcaption>
</figure>

<h4>Entire Data Collection Procedure</h4>
<figure>

	<table>
		<tr>
			<td>
				<img src="images/fchar1.png" alt="Frequency Characterization 1" class="fchar" />
			</td>
		</tr>
		<tr>
			<td>
				<img src="images/fchar2.png" alt="Frequency Characterization 2" class="fchar" />
			</td>
		</tr>
		<tr>
			<td>
				<img src="images/fchar3.png" alt="Frequency Characterization 3" class="fchar" />
			</td>
		</tr>
	</table>
	<figcaption>Characterization of Obtained Data, Showing the Results of Participants Applying Various Amounts of Subjective Force</figcaption>
</figure>

<p>In summary, we performed all of our recordings using the commercially available MyoDynamik CURO (Figure 1), with the large equine AMG sensors depicted. For our recordings, we affixed a sensor to the center of the biceps, with ultrasound gel for noise insulation. Each subject was instructed to sit straight up with their elbow at a 90-degree angle, palms facing up. During the trial, subjects were told to perform isometric (motionless) contractions by pushing up against the bottom of a weighted table, using a subjective fraction of their total strength in increments of 20% for roughly 2-4 seconds, with 2-4 second rest periods in between contractions (Figure 2). We gathered a total of 25 trials from 8 subjects. All trials for any particular subject were taken back-to-back with a 1-minute rest period, without removing or replacing the sensor.</p>


<h3>Post-Signal Processing</h3>
<p>To identify a method for decoding force intent given a raw AMG signal, we decided to look at three parameters of the signal: amplitude, frequency, and the amplitude-frequency product. Signal amplitude was expected to relate to the spatial summation of muscle fiber firings (i.e. the number of fibers recruited), while frequency was related to temporal summation of muscle fiber firings, which controls the extent of muscle contraction. Software designed for the CURO is capable of calculating a proprietary ESTi score, which is effectively a product of spatial and temporal summation parameters, that has been shown to correlate linearly with muscle output power or force [1]. As a result, our hypothesized relationship is summarized in (1), where $Fout$ is the muscle output force, $n$ is the number of recruited fibers, $Favg$ is the average fiber output force, $A$ is the amplitude, $nu$ is the frequency, and $\alpha$ is a constant.</p>


<img src="images/equation.png" alt="Force is in theory proportional to amplitude and frequency" id="equation" />


<p>For each of our 25 trials, we detrended the raw signal, removed outliers, and delineated the start and end of each contraction period manually. For the amplitude parameter, we took the difference between the upper and lower root-mean-square envelopes of the signal using a 1000-sample (0.5 s) window (Figure 3A), and calculated the mean amplitude for each contraction period. Due to individual variations in signal strength, we scaled each signal such that the mean amplitude at baseline (0% contraction) was set at 1.</p>

<figure>
<img src="images/env_detection.png" alt="Graph showing envelope detection example" />
<figcaption>Envelope Detection Applied to Sample Data</figcaption>
</figure>


<p>To determine the frequency parameter, we took each individual contraction period, and multiplied it with a Hann window of the same length, to reduce spectral leakage around active frequencies. We then used MATLAB's meanfreq function to calculate the mean frequency of each contraction period between 2 and 500 Hz (Figure 3B), which encapsulates the full working frequencies of active muscle [1]. Because rapid spikes/outliers are strongly delocalized in the frequency domain, much care needed to be taken to remove them manually.</p>

<figure>
	<img src="images/mean_freq.png" alt="Mean Frequency Calculation" />
	<figcaption>Mean Frequency Calculated within Specified Bounds</figcaption>
</figure>

<h3>Signal Processing Analysis</h3>

<figure>
	<table>
		<tr>
			<td>
	<img src="images/indv_amp.png" alt="Graph of Individual Participant Amplitude" />
</td>
<td>
	<img src="images/grouped_amp.png" alt="Graph of Overall Amplitudes" />
</td>
</tr>
</table>
<figcaption>Graphs of Change in Ampltiude in Response to Changes of Force</figcaption>
</figure>


<figure>
	<table>
		<tr>
			<td>
	<img src="images/indv_freq.png" alt="Graph of Individual Participant Frequency" />
</td>
<td>
	<img src="images/group_freq.png" alt="Graph of Overall Frequencies" />
</td>
</tr>
</table>
<figcaption>Graphs of Change in Frequency in Response to Changes of Force</figcaption>
</figure>

<figure>
	<table>
		<tr>
			<td>
	<img src="images/freq_amp.png" alt="Graph of Individual Participant Frequency-Amplitude Product" />
</td>
<td>
	<img src="images/freq_amp_grouped.png" alt="Graph of Overall Frequency-Amplitude Products" />
</td>
</tr>
</table>
<figcaption>Graphs of Change in Frequency-Amplitude Product in Response to Changes of Force</figcaption>
</figure>





<h3>Simulation Experimental Setup</h3>
<p>To determine if we could utilize a force input signal, <em>u(t)</em>, to control the contact forces on an object grasped by a robot's grippers, we utilized PyBullet as a simulation environment. We used a 7 degree-of-freedom KUKA robot situated on a table as the robot performing our grasp task in simulation. We also designed a custom gripper to be the end-effector for the KUKA robot, which simply consisted of a rectangular prism base with two gripper rods attached as shown in Figure 4. The gripper has two prismatic joints, allowing each one of the gripper rods to slide along the base freely until colliding with the other gripper rod.</p>

<figure>
	<div>
<img src="images/simulation_setup.png" alt="Simulation Setup" />
</div>
<figcaption>Full simulation setup, with KUKA robot, gripper, and Jenga block shown.</figcaption>
</figure>
<p>The PyBullet simulator allows for position, velocity, and torque control of all robot joints, which extended to the gripper rods utilized to grasp an object. However, due to inconsistencies in the characterization of velocity and torque control, the latter of which would directly control the acceleration of the gripper rod since it is attached to a prismatic joint, we were not able to run experiments with velocity and torque control. As a result, we carried out two sets of experiments using position control of the gripper rods.</p>
<p>The first set of experiments characterized the average contact force exerted on an object using feedforward position control. The test simulation would first position the robot arm such that the attached gripper is 10 cm above the object to be grasped; here, we used a Jenga block that is 15 x 5 x 3 cm, and our robot was grasping along the 3 cm dimension. The combined setup is also depicted in Figure 4. From there, the arm would descend 10 cm, and begin to close the grippers until the gripper rods made contact with the Jenga block. After contact was made, position control was initiated by instructing the grippers to penetrate deeper into the block by $x$ cm, where $x$ cm is the feedforward position control input, also described as the gripper intrusion depth. At extremely small $x$ values, the grippers would fail to maintain contact with the Jenga block, and at extremely high $x$ values, the grippers would crush the Jenga block out of its grasp, which was the reasoning behind focusing the characterization on the range discussed in the results. We conducted three trials at each $x$ value. While the gripper rods were in contact with the block, the contact forces would be measured by PyBullet at each contact point for each timestep, and the mean $\pm$ standard deviation of these contact forces was reported. During the measuring process, the wooden block was also raised up by 10 cm to the robot's original position to ensure that a stable grasp was achieved.</p>
<p>The next set of experiments utilized proportional feedback position control to track an input force signal $u(t)$. In this case, we specified a goal contact force in Newtons, and the gripper penetration depth from the previous experiment was varied as the feedforward input to achieve the target force. At each timestep, the error between the desired force and the current force is multiplied by 10$^{-4}$ and this value is then added to the current gripper penetration depth. We utilized a variety of input force trajectories, ranging from sine waves to sawtooth waves and square waves. For each test, we utilized amplitudes, $A$, varying from 1 to 32 Newtons, and centered each wave at a DC value of 2$A$. We performed most experiments with amplitudes at $A$/4, but also tested certain simulations with amplitudes at $A$. For each timestep in the experiment, the average contact force across all contact points was reported.</p>
<h2>Results</h2>
<h3>Force Decoding</h3>
<p>The results of our 25 trials are depicted in Figure 5, with both individual and grouped data. We observed a significant nonlinear relationship between reported contraction strength and both signal amplitude and amplitude-frequency product ($p < 0.0001$), although the fact that we observed no similar relationship with frequency ($p = 0.2918$) suggests that the amplitude relationship is the only valid one. In addition to differences between signal features and contraction effort, two-way ANOVA on the individually-matched datasets also showed significant differences in signal features between users ($p \leq 0.0004$), as well as a significant effect of subject-effort interaction on signal features ($p < 0.0001$), for all three feature types. These results suggest that a high level of variation in system behavior between different users was present, which was no surprise, given the individual variations expected in user strength, anatomy, and sensor attachment location.</p>

<h3>Force Control in Simulation</h3>

<figure>
<video controls="controls" width="1920" height="1080">
	<source src="videos/Feedforward.mp4" type="video/mp4" />
</video>
<figcaption>Demonstration of robot grasping a cube using feedforward control at 10.5 mm intrusion depth.</figcaption>
</figure>
<figure>
<video controls="controls" width="1920" height="1080">
	<source src="videos/Force%20Videos%20Feedforward%20position.mp4" type="video/mp4" />
</video>
<figcaption>Demonstration of robot grasping a jenga block using feedforward control at 10.5, 13, and 10 mm intrusion depth.</figcaption>
</figure>
<figure>
<img src="images/force%20vs%20gripper%20position.png" alt="description" width="648" height="546" />
<figcaption>Average contact force vs. gripper feedforward position control characterization.</figcaption>
</figure>
<p>The results from the feedforward position control experiment are shown in Figure 6. As the gripper intrusion depth increased from 10 mm, where it lost contact with the Jenga block, to 15 mm, where the block was crushed so hard that it flew out of the grippers, we saw a roughly linear increase in average contact force. Of note is that at very high contact forces, the variation in contact forces is extremely high. This is likely because some trials at these gripper intrusion depths involved the block getting squeezed out of the grippers' grasp. Other trials in this range likely had the block move ever so slightly, resulting in what would be small variations in contact forces at low gripper intrusion depths, but since the intrusion depth was so high for these trials, these slight changes in position caused huge fluctuations in the average contact forces on the block. Despite the large variations at higher forces, this set of experiments demonstrated that within a specific regime, we could directly and linearly control the contact forces experienced by a block by varying the gripper position, and that this control might be more accurate at lower contact forces.</p>

<figure>
<video controls="controls" width="1920" height="1080">
	<source src="videos/Sawtooth.mp4" type="video/mp4" />
	<p>Demonstration of robot grasping a jenga block with a sawtooth input force trajectory at 32 N amplitude. Minor deviations in the green gripper rod's position can be noted.</p>
</video>
	<figcaption></figcaption>
</figure>

<figure>
<img src="images/example_waves.png" alt="Example Wave Control Input" />
<figcaption>Observed average contact force on block vs. time with proportional feedback gripper position control for Left: 1 Hz sine Wave with 32 N amplitude centered at 64 N, Middle: 1 Hz sawtooth wave with 4 N amplitude centered at 32 N, Right: 1 Hz square wave with amplitude 0.5 N centered at 4 N.</figcaption>
</figure>
<p>Three example graphs depicting results of the proportional feedback position control experiment are shown in Figure 7. In these experiments, we made the desired input force trajectories sine, sawtooth, or square waves at 1 Hz with amplitudes $A$ ranging from 1 to 32 Newtons centered at 2$A$. We found that the average contact force generally tracks the desired contact force relatively well across each trajectory. The amplitudes and DC value are exactly as expected across the different amplitudes, ranging from the low force case of 1 N all the way to the maximum of about 100 N in the 32 N case. However, there is a bit of a discrepancy in the exact frequency of the output wave. Most of the waves appear to have a period of about 1.1-1.2 seconds, which means that the frequency of the experienced average contact force trajectory varies between 0.83 and 0.91 Hz, instead of the expected 1 Hz wave. However, since all simulations regardless of input force trajectory have this shift in expected frequency from 1 Hz to slightly less than 1 Hz, this suggests that this may be a discrepancy caused by simulation in PyBullet, or by intermediate calculations in the simulation causing a systemic slow-down effect.</p>
<p>Of special note are the square wave experiments because the sudden discontinuities in the square wave trajectory would largely mimic a human user's force trajectory when grasping an object remotely: they would start at a very low force, and quickly reach the force necessary to grasp the object and remain at that steady-state force value. We found that the measured force trajectory strongly matched the desired force input $u(t)$ with minor overshoot before settling to the correct steady-state value. In addition, the aforementioned minor changes in frequency and some transient stutters in the output force in the 32 N experiment were present. Overall, the simulation results suggest that the proportional feedback position control works very effectively both at maintaining steady-state forces and quickly adapting to sudden changes in desired force. In addition to the sine and square wave trajectories, we tested out sawtooth waves at the same amplitudes, in which we saw similar overshoot and settling as seen in the square waves.
<h2>Conclusion</h2>

<h2>Team Bios</h2>

<h3 class="profileheader">Chris Mitchell</h3>
<p>Chris is an Electrical Engineeering and Computer Science (EECS) major doubling in Linguistics at UC Berkeley, class of 2020. His primary research interests involve applying the combination of robotics and interdisciplinary techniques in order to progress the biomedical field and improve assistive technology.
	</p>

<h3 class="profileheader">Eric Hu</h3>
<p>

	</p>

<h3 class="profileheader">Fayyaz Ahamed</h3>

<p>Fayyaz is a senior majoring in bioengineering who has taken EECS C106A, the BioE equivalents of 16A/B, EE120, and has research experience in biomedical imaging. He has experience working with EEG and is interested in robotic surgery and improving human-robot interaction.</p>


</body>

<!--[if IE lte 8]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->


</html>