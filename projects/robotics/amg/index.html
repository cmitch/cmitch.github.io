<!DOCTYPE html>
<html>
<head>

<meta charset="UTF-8">
<meta name="description" content="UC Berkeley Research into Acoustic Myography as a Valid Force Signal for Assitive Devices">
<meta name="keywords" content="CS,EE,EECS,BioE,bioengineering,robotics,amg,medical,prosthetics,exoskeletal,Berkeley,graphics,control" >
<meta name="author" content="Chris Mitchell, Eric Hu, Fayyaz Ahamed">

<link href="assets/css/main.css" rel="stylesheet" type="text/css" />

<link href="amg.css" rel="stylesheet" type="text/css" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<title>EECS 106B AMG Project</title>
</head>

<body>
<h1>EECS 106B: Acoustic Myography (AMG) for Robotic Force Control</h1>
<h6>Chris Mitchell, Eric Hu, Fayyaz Ahamed</h6>

<h2>Project Overview</h2>
<figure>
	<table>
		<tr>
			<td>
				<img src="images/holding_egg.png" alt="Example of prosthetic holding delicate object" />
			</td>
			<td>
				<img src="images/surgery.png" alt="Example of robots assiting in surgery" />
			</td>
		</tr>
	</table>
	<figcaption>Applications of robotic force control in the biomedical field</figcaption>
</figure>

<p>
Robotics has been slowly becoming a staple in the medical field. While sensing technologies such as MRI, EMG, and ultrasounds have been around for decades, with recent advancements in artificial intelligence, control theory, and grasp theory, more complex human-machine interactions have been made possible, allowing for the development of assistive surgery, advanced prosthetics, and exoskeletons. Force is a central component to the control of these systems, since while a system should avoid harming the user or damaging objects, there exists a baseline amount of force required to engage in these tasks. While a human can intuitively apply and adjust their exerted forces, this problem is much more difficult for a robot to solve: even a machine learning approach would require a multitude of trials to provide adequate training data.
	</p>
<h3>What is AMG?</h3>
<table>
	<tr>
		<td>
<figure>
	<img src="images/horse_curo.png" alt="Use of AMG on a horse" />
	<figcaption>AMG in Use</figcaption>
</figure>
</td>
<td>
<figure>
	<img src="images/muscle_fibers.png" alt="Diagram of muscle fibers" />
	<figcaption>AMG listens to the acoustic vibrations of muscle fibers</figcaption>
</figure>
</td>
</tr>
</table>

<p>
	AMG is essentially a glorified microphone, functioning like a muscle stethoscope. Just as an EMG senses differences in voltage, an AMG senses the mechanical/acoustic waves produced by one's arm during muscle contraction. Like sEMG, this technique has proven to be reliable, low-cost, and noninvasive, allowing it to work as an onboard sensor for assistive devices with minimal hinderance. Note that for the purposes of our experiments, we used AMG sensors designed for equine subjects throughout this project.
	</p>

<h3>Goal of Project</h3>

<p>
	Prior work has suggested a mathematical relationship between the features of the AMG signal and the force the muscle is exerting. Our aim is to use this signal as a feedforward control input into a robot. From this foundation, the user could control the force a robot uses for tasks such as grasping both rigid and soft objects, compensatory force application, or indirect control. Due to the university shutdown and lack of access to hardware, we sought to implement this force control with a simulated robotic grasp, using the AMG force signal as the desired contact force.

<figure>
	<img src="images/flow_chart.png" alt="Control Flow Chart" />
	<figcaption>AMG Force Control Flow Chart</figcaption>
</figure>

<h2>Implementation</h2>
<p> Our code repository is located <a href="https://github.com/cmitch/final_proj_106b">here</a> and our report is located <a href="EECS106B_Final_Report.pdf">here</a>.
<h3>AMG Experimental Setup</h3>
<p>
<p>We performed all of our recordings using the commercially available MyoDynamik CURO (Figure 1), with the large equine AMG sensors depicted. For our recordings, we affixed a sensor to the center of the biceps, with ultrasound gel for noise insulation. Each subject was instructed to sit straight up with their elbow at a 90-degree angle, palms facing up. During the trial, subjects were told to perform isometric (motionless) contractions by pushing up against the bottom of a weighted table, using a subjective fraction of their total strength in increments of 20% for roughly 2-4 seconds, with 2-4 second rest periods in between contractions (Figure 2). We gathered a total of 25 trials from 8 subjects. All trials for any particular subject were taken back-to-back with a 1-minute rest period, without removing or replacing the sensor.</p>


<h3>Data Collection Method</h3>
<h4>Sensor Setup</h4>
<p>The AMG sensors we obtained came with the MyoDynamik CURO box, a device that allows for multi-channel AMG sampling and recording. These signals are then converted into a WAV file for post-processing.

<figure>
	<img src="images/curobox_setup.png" alt="CURO Setup" />
	<figcaption>Original setup using CURO box</figcaption>
</figure>

<p>
	While the CURO provides ease in functionality, it lacks any real-time support that we would desire for an applied system. For this reason, we also explored rerouting the signal directly from the sensor into an Arduino. After the sensor's built in amplifier, we further amplified, low pass filtered, and buffered the signal before sampling.
	</p>

<table>
	<tr>
		<td>
			<figure>
			<img src="images/circuitry.png" alt="Arduino Sensor Circuitry" />
			<figcaption>Post-processing circuitry</figcaption>
		</figure>
		</td>
		<td>
			<figure>
				<img src="images/arduino_sensor_setup.png" alt="Arduino Sensor Setup" />
				<figcaption>Arduino sensor setup</figcaption>
			</figure>
		</td>
	</tr>
</table>
<h4>Real-Time versus Pre-Processing</h4>

<p>While our experiments with the real time data collection show promise, the data clearly appears cleaner with the CURO, as seen below. Note that the amplitude is irrelevant for this case due to differences in gain between both implementations; additionally, we suspect that the CURO performs some processing we could not replicate. The CURO also samples at the high rate of 2 kHz, which would require setting changes for an Arduino to effectively replicate. For these reasons, we settled on using the CURO for our preliminary analysis.

<figure>
<table>
	<tr>
		<td>
			<img src="images/realtime_data.png" alt="Real-Time Data" class="realtimedata"/>
		</td>
		<td>
			<img src="images/curobox_sample_data.png" alt="CURO Preprocessed Data" class="realtimedata" />
		</td>
	</tr>
</table>

<figcaption>Real-time versus CURO-processed data</figcaption>
</figure>

<h4>Choosing Isometric Contractions</h4>
<p>For experimental design, we decided on using isometric contractions, or contractions where the arm is relatively stationary. While non-isometric results, such as with lifting a weight, could be highly informative, the onset and end of such actions creates impulses that would need to be taken into account. For this reason, we stayed with isometric experimentation by having a user apply a subjective amount of force against a table without removing their hand, and measuring the mechanical output of the bicep.
<figure>
<table>
	<tr>
		<td>
			<img src="images/iso_setup.png" alt="Isometric Setup" class="isosetup" />
		</td>
		<td>
			<img src="images/nonIsoSetup.png" alt="Non-Isometric Setup" class="isosetup"/>
		</td>
	</tr>
</table>
<figcaption>Isometric versus non-isometric setup</figcaption>
</figure>

<figure>
<table>
	<tr>
		<td>
			<img src="images/iso_data.png" alt="Isometric Data" class="isodata"/>
		</td>
		<td>
			<img src="images/non_iso_data.png" alt="Non-Isometric Data" class="isodata" />
		</td>
	</tr>
</table>

<figcaption>Isometric versus non-isometric data</figcaption>
</figure>

<h4>Data Collection Protocol</h4>
<figure>

	<table>
		<tr>
			<td>
				<img src="images/fchar1.png" alt="Frequency Characterization 1" class="fchar" />
			</td>
		</tr>
		<tr>
			<td>
				<img src="images/fchar2.png" alt="Frequency Characterization 2" class="fchar" />
			</td>
		</tr>
		<tr>
			<td>
				<img src="images/fchar3.png" alt="Frequency Characterization 3" class="fchar" />
			</td>
		</tr>
	</table>
	<figcaption>Characterization of obtained data, with participants exerting various amounts of subjective force</figcaption>
</figure>

<p>In summary, we performed all of our recordings using the commercially available MyoDynamik CURO (Figure 1), with the large equine AMG sensors depicted. For our recordings, we affixed a sensor to the center of the biceps, with ultrasound gel for noise insulation. Each subject was instructed to sit straight up with their elbow at a 90-degree angle, palms facing up. During the trial, subjects were told to perform isometric (motionless) contractions by pushing up against the bottom of a weighted table, using a subjective fraction of their total strength in increments of 20% for roughly 2-4 seconds, with 2-4 second rest periods in between contractions (Figure 2). We gathered a total of 25 trials from 8 subjects. All trials for any particular subject were taken back-to-back with a 1-minute rest period, without removing or replacing the sensor.</p>


<h3>Post-Signal Processing</h3>
<p id="psp">To identify a method for decoding force intent given a raw AMG signal, we decided to look at three parameters of the signal: amplitude, frequency, and the amplitude-frequency product. Signal amplitude was expected to relate to the spatial summation of muscle fiber firings (i.e. the number of fibers recruited), while frequency was related to temporal summation of muscle fiber firings, which controls the extent of muscle contraction. Software designed for the CURO is capable of calculating a proprietary ESTi score, which is effectively a product of spatial and temporal summation parameters, that has been shown to correlate linearly with muscle output power or force [1]. As a result, our hypothesized relationship is summarized in (1), where $Fout$ is the muscle output force, $n$ is the number of recruited fibers, $Favg$ is the average fiber output force, $A$ is the amplitude, $nu$ is the frequency, and $\alpha$ is a constant.</p>

<!--
<img src="images/equation.png" alt="Force is in theory proportional to amplitude and frequency" id="equation" />

-->

<div id="equation">$F_m = n F_f = \alpha A v$</div>


<p>For each of our 25 trials, we detrended the raw signal, removed outliers, and delineated the start and end of each contraction period manually. For the amplitude parameter, we took the difference between the upper and lower root-mean-square envelopes of the signal using a 1000-sample (0.5 s) window (Figure 3A), and calculated the mean amplitude for each contraction period. Due to individual variations in signal strength, we scaled each signal such that the mean amplitude at baseline (0% contraction) was set at 1.</p>

<figure>
<img src="images/env_detection.png" alt="Graph showing envelope detection example" />
<figcaption>Envelope detection applied to sample data</figcaption>
</figure>


<p>To determine the frequency parameter, we took each individual contraction period, and multiplied it with a Hann window of the same length, to reduce spectral leakage around active frequencies. We then used MATLAB's meanfreq function to calculate the mean frequency of each contraction period between 2 and 500 Hz (Figure 3B), which encapsulates the full working frequencies of active muscle [1]. Because rapid spikes/outliers are strongly delocalized in the frequency domain, much care needed to be taken to remove them manually.</p>

<figure>
	<img src="images/mean_freq.png" alt="Mean Frequency Calculation" />
	<figcaption>Mean frequency calculated within specified bounds</figcaption>
</figure>

<h3>Signal Processing Analysis</h3>

<figure>
	<table>
		<tr>
			<td>
	<img src="images/indv_amp.png" alt="Graph of Individual Participant Amplitude" />
</td>
<td>
	<img src="images/grouped_amp.png" alt="Graph of Overall Amplitudes" />
</td>
</tr>
</table>
<figcaption>Graphs of change in ampltiude in response to changes of force</figcaption>
</figure>


<figure>
	<table>
		<tr>
			<td>
	<img src="images/indv_freq.png" alt="Graph of Individual Participant Frequency" />
</td>
<td>
	<img src="images/group_freq.png" alt="Graph of Overall Frequencies" />
</td>
</tr>
</table>
<figcaption>Graphs of change in frequency in response to changes of force</figcaption>
</figure>

<figure>
	<table>
		<tr>
			<td>
	<img src="images/freq_amp.png" alt="Graph of Individual Participant Frequency-Amplitude Product" />
</td>
<td>
	<img src="images/freq_amp_grouped.png" alt="Graph of Overall Frequency-Amplitude Products" />
</td>
</tr>
</table>
<figcaption>Graphs of change in frequency-amplitude product in response to changes of force</figcaption>
</figure>





<h3>Simulation Setup</h3>
<p>To determine if we could utilize a force input signal, <em>u(t)</em>, to control the contact forces on an object grasped by a robot's grippers, we utilized PyBullet as a simulation environment. We used a 7 degree-of-freedom KUKA robot situated on a table as the robot performing our grasp task in simulation. We also designed a custom gripper to be the end-effector for the KUKA robot, which simply consisted of a rectangular prism base with two gripper rods attached as shown in Figure 4. The gripper has two prismatic joints, allowing each one of the gripper rods to slide along the base freely until colliding with the other gripper rod. We carried out two sets of experiments using position control of the gripper rods.</p>

<figure>
	<div>
<img src="images/simulation_setup.png" alt="Simulation Setup" />
</div>
<figcaption>Full simulation setup, with KUKA robot, gripper, and Jenga block shown.</figcaption>
</figure>
<p>The first set of experiments characterized the average contact force exerted on an object using feedforward position control. The test simulation would first position the robot arm such that the attached gripper is 10 cm above the object to be grasped; here, we used a Jenga block that is 15 x 5 x 3 cm, and our robot was grasping along the 3 cm dimension. The combined setup is also depicted in Figure 4. From there, the arm would descend 10 cm, and begin to close the grippers until the gripper rods made contact with the Jenga block. After contact was made, position control was initiated by instructing the grippers to penetrate deeper into the block by $x$ cm, where $x$ cm is the feedforward position control input, also described as the gripper intrusion depth. At extremely small $x$ values, the grippers would fail to maintain contact with the Jenga block, and at extremely high $x$ values, the grippers would crush the Jenga block out of its grasp, which was the reasoning behind focusing the characterization on the range discussed in the results. We conducted three trials at each $x$ value. While the gripper rods were in contact with the block, the contact forces would be measured by PyBullet at each contact point for each timestep, and the mean $\pm$ standard deviation of these contact forces was reported. During the measuring process, the wooden block was also raised up by 10 cm to the robot's original position to ensure that a stable grasp was achieved.</p>
<p>The next set of experiments utilized proportional feedback position control to track an input force signal $u(t)$. In this case, we specified a goal contact force in Newtons, and the gripper penetration depth from the previous experiment was varied as the feedforward input to achieve the target force. At each timestep, the error between the desired force and the current force is multiplied by 10$^{-4}$ and this value is then added to the current gripper penetration depth. We utilized a variety of input force trajectories, ranging from sine waves to sawtooth waves and square waves. For each test, we utilized amplitudes, $A$, varying from 1 to 32 Newtons, and centered each wave at a DC value of 2$A$. We performed most experiments with amplitudes at $A$/4, but also tested certain simulations with amplitudes at $A$. For each timestep in the experiment, the average contact force across all contact points was reported.</p>
<h2>Results</h2>
<h3>Force Decoding</h3>
<p>The results of our 25 trials are depicted in Figure 5, with both individual and grouped data. We observed a significant nonlinear relationship between reported contraction strength and both signal amplitude and amplitude-frequency product ($p < 0.0001$), although the fact that we observed no similar relationship with frequency ($p = 0.2918$) suggests that the amplitude relationship is the only valid one. In addition to differences between signal features and contraction effort, two-way ANOVA on the individually-matched datasets also showed significant differences in signal features between users ($p \leq 0.0004$), as well as a significant effect of subject-effort interaction on signal features ($p < 0.0001$), for all three feature types. These results suggest that a high level of variation in system behavior between different users was present, which was no surprise, given the individual variations expected in user strength, anatomy, and sensor attachment location.</p>

<h3>Force Control in Simulation</h3>

<figure>
<video controls="controls" width="1920" height="1080">
	<source src="videos/Feedforward.mp4" type="video/mp4" />
</video>
<figcaption>Demonstration of robot grasping a cube using feedforward control at 10.5 mm intrusion depth.</figcaption>
</figure>
<figure>
<video controls="controls" width="1920" height="1080">
	<source src="videos/Force%20Videos%20Feedforward%20position.mp4" type="video/mp4" />
</video>
<figcaption>Demonstration of robot grasping a jenga block using feedforward control at 10.5, 13, and 10 mm intrusion depth.</figcaption>
</figure>
<figure>
<img src="images/force%20vs%20gripper%20position.png" alt="description" width="648" height="546" />
<figcaption>Average contact force vs. gripper feedforward position control characterization.</figcaption>
</figure>
<p>The results from the feedforward position control experiment are shown in Figure 6. As the gripper intrusion depth increased from 10 mm, where it lost contact with the Jenga block, to 15 mm, where the block was crushed so hard that it flew out of the grippers, we saw a roughly linear increase in average contact force. Of note is that at very high contact forces, the variation in contact forces is extremely high. This is likely because some trials at these gripper intrusion depths involved the block getting squeezed out of the grippers' grasp. Other trials in this range likely had the block move ever so slightly, resulting in what would be small variations in contact forces at low gripper intrusion depths, but since the intrusion depth was so high for these trials, these slight changes in position caused huge fluctuations in the average contact forces on the block. Despite the large variations at higher forces, this set of experiments demonstrated that within a specific regime, we could directly and linearly control the contact forces experienced by a block by varying the gripper position, and that this control might be more accurate at lower contact forces.</p>

<figure>
<video controls="controls" width="1920" height="1080">
	<source src="videos/Sawtooth.mp4" type="video/mp4" />
</video>
	<figcaption>Demonstration of robot grasping a jenga block with a sawtooth input force trajectory at 32 N amplitude. Minor deviations in the green gripper rod's position can be noted.</figcaption>
</figure>

<figure>
<img src="images/example_waves.png" alt="Example Wave Control Input" />
<figcaption>Observed average contact force on block vs. time with proportional feedback gripper position control for Left: 1 Hz sine Wave with 32 N amplitude centered at 64 N, Middle: 1 Hz sawtooth wave with 4 N amplitude centered at 32 N, Right: 1 Hz square wave with amplitude 0.5 N centered at 4 N.</figcaption>
</figure>
<p>Three example graphs depicting results of the proportional feedback position control experiment are shown in Figure 7. Supplemental data is located <a href="supplemental_data.html">here</a>. In these experiments, we made the desired input force trajectories sine, sawtooth, or square waves at 1 Hz with amplitudes $A$ ranging from 1 to 32 Newtons centered at 2$A$. We found that the average contact force generally tracks the desired contact force relatively well across each trajectory. The amplitudes and DC value are exactly as expected across the different amplitudes, ranging from the low force case of 1 N all the way to the maximum of about 100 N in the 32 N case. However, there is a bit of a discrepancy in the exact frequency of the output wave. Most of the waves appear to have a period of about 1.1-1.2 seconds, which means that the frequency of the experienced average contact force trajectory varies between 0.83 and 0.91 Hz, instead of the expected 1 Hz wave. However, since all simulations regardless of input force trajectory have this shift in expected frequency from 1 Hz to slightly less than 1 Hz, this suggests that this may be a discrepancy caused by simulation in PyBullet, or by intermediate calculations in the simulation causing a systemic slow-down effect.</p>
<p>Of special note are the square wave experiments because the sudden discontinuities in the square wave trajectory would largely mimic a human user's force trajectory when grasping an object remotely: they would start at a very low force, and quickly reach the force necessary to grasp the object and remain at that steady-state force value. We found that the measured force trajectory strongly matched the desired force input $u(t)$ with minor overshoot before settling to the correct steady-state value. In addition, the aforementioned minor changes in frequency and some transient stutters in the output force in the 32 N experiment were present. Overall, the simulation results suggest that the proportional feedback position control works very effectively both at maintaining steady-state forces and quickly adapting to sudden changes in desired force. In addition to the sine and square wave trajectories, we tested out sawtooth waves at the same amplitudes, in which we saw similar overshoot and settling as seen in the square waves.

<h2>Conclusion</h2>

<p>Based on our force response characterization, we conclude that there is a roughly parabolic relationship between AMG rms signal amplitude and user-reported muscle force, and no relationship with frequency. The fact that we see no difference in frequency could be due to an error in attaching the sensors during recording, or a lack of robust filtering during the data processing stage; as mentioned previously, the presence of small spikes or impulses can quickly skew the entire signal spectrum toward much higher frequencies, and shift the average.
	</p>
<p>Originally, we planned to correlate AMG signal parameters with the actual magnitude of force exerted by the user. However, due to the difficulty of measuring muscle tension and output force in real-time, we ended up correlating the signal parameters to subjective effort levels instead. While this approach prevents us from ascertaining any fixed relationship between AMG signal and output force, it has one major benefit: it allows us to gauge AMG characteristics with respect to the user's expected output force, instead of their actual output force, meaning that the approach naturally accounts for errors between these forces. This means that a user operating our system could control a decoded force output that feels linear, even if the physical forces involved are actually quadratic.
	</p>
<p>In seeking to actuate a force input signal $u(t)$, we designed a robust proportional feedback position controller in simulation. We found that across a variety of signal amplitudes and trajectories, the contact forces closely matched the desired input force trajectory, with the only minor drawback being a slight decrease in frequency. Unfortunately, there are several aspects of our simulation that may prevent our results from working identically on physical platforms. Our proportional feedback utilized the difference between the desired force and the current average contact force to conduct error correction. In simulation, we have perfect knowledge of those contact forces; however, in reality, we would require some sort of sensor attached to either the wooden block or the grippers to provide a real-time estimate of the contact force. Alternatively, we could calculate the grasping contact forces based on torques applied at the joints. Nevertheless, there will always some uncertainty in the real-time force value returned to the controller by either of these methods, which will make our controller less reliable in reality.
	</p>

<h2>Future Work</h2>

<p>Our goal for this project is to be able to directly control the strength of a grasp force in real time using inputs decoded from AMG sensor recordings, both in simulation as well as on a physical robot platform. To this end, our intended next steps are to configure the AMG sensors in such a way that they can capture data in real time. In practice, this would require not only adjustments to the filtering and data processing pipelines, but also an $n$-point calibration of the AMG signal response before the start of every real-time recording, to which a quadratic curve can be fitted using least-squares. From there, real-time amplitude measurements can simply be plugged into the curve to determine the user's force intent.
	</p>
<p>If current circumstances persist and we are unable to access a physical robot, there are several improvements we could make to the simulator. The first improvement would be to test out objects of different mass and volume, examine what changes in force control might be necessary to resist varied gravitational forces. The next major step would be to sample human user AMG data after user calibration to feed into the simulator as the desired force input $u(t)$. If the robot is able to track the human user's intent without much modification to our current design, we would finally attempt to collect an AMG datastream, and use it to control the simulation robot in real-time.
	</p>

<h2>Team Bios</h2>

<h3 class="profileheader">Chris Mitchell</h3>
<p>Chris is an Electrical Engineeering and Computer Science (EECS) major doubling in Linguistics at UC Berkeley, class of 2020. His primary research interests involve applying the combination of robotics and interdisciplinary techniques in order to progress the biomedical field and improve assistive technology.
	</p>

<h3 class="profileheader">Eric Hu</h3>
<p>Eric is a senior majoring in Bioengineering with a minor in EECS, who has taken courses on robotics (EECS C106A), digital signal processing (EE 120/123), and human-oriented design (BioE C137). He has experience with EMG systems, and is interested in designing neuroprosthetics and brain-machine interfaces.

	</p>

<h3 class="profileheader">Fayyaz Ahamed</h3>

<p>Fayyaz is a senior majoring in Bioengineering who has taken EECS C106A, the BioE equivalents of 16A/B, EE120, and has research experience in biomedical imaging. He has experience working with EEG and is interested in robotic surgery and improving human-robot interaction.</p>


</body>

<!--[if IE lte 8]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->


</html>