<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Chris Mitchell - Ray Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<meta name="description" content="Chris Mitchell's website">
<meta name="keywords" content="CS,EE,EECS,linguistics,Berkeley">
<meta name="author" content="Chris Mitchell">
	
<link href="../../../common.css" rel="stylesheet" type="text/css">
</head>
<body>
	<nav>	
<ul id="navmenu">
	<li class="navitem"><a class="navlink" href="../../../index.html" >Home</a></li>
	<li class="navitem"><a class="navlink" href="../../index.html">Projects</a></li>
	<li class="navitem"><a class="navlink" href="../../../classes.html">Relevant Coursework</a></li>
	<li class="navitem"><a class="navlink" href="https://www.linkedin.com/in/christopher-mitchell-270b1611b/" target="_blank">LinkedIn</a></li>
	</ul>
</nav>
<br />
<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
<h1 align="middle">Project 3: Ray Tracer</h1>
<h2 align="middle">Chris Mitchell, UC Berkeley</h2>



    <h2 align="middle">Part 1: Ray Generation and Intersection</h2>
        <p>In part 1, I generated rays to pass through each pixel, calculated their intersections, and used this information to determine how illuminated each pixel should be. </p>
        <p>
            Ray generation consisted of generating random points within the frame of the pixel for each sample we wanted. From here, I transformed the rays to be in the camera space and finally to the world space. This mainly involved affine transformations based on the position and angles of the camera. Each ray is then passed into another function to estimate the total global illumination, which are all averaged and return to determine the color intensity for each pixel.
        </p>

        <p>
           I implemented ray intersections for both triangles and spheres. For triangles, I applied the <a href="www.scratchpixel.com/lessons/3d-basic-rendering/ray-tracing-rendering-a-triangle/moller-trumbore-ray-triangle-intersection" >Moller Trumbore Algorithm </a>, which, in a manner similar to barycentric coordinates, allowed me to calculate where the ray would intersect the triangle relative to the vertices and also relative to the ray's path. If either of these intersection locations were invalid, whether the ray location is invalid or the location within the triangle, the ray doesn't intersect with the triangle. If it does intersect, then I updated the intersect information for the rest of the code to be able to calculate the color of the subpixel point.
        </p>

        <p>
            For spheres, I used a similar algorithm to Moller Trumbore. Recognizing that a ray can be written as:
        </p>

        <p align="middle"><pre align="middle">r(t) = o + td, 0 <= t < inf</pre></p>
        <p> 
            and that all points on a sphere satisfy:
        </p>

        <p align="middle"><pre align="middle">(p - c)^2 = R^2</pre></p>
        <p>
            I solved the resulting quadratic and checked the possible intersection points to see if any were valid, and if so, which one is the first intersection.
        </p>
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part1CBSpheres.png" width="480px" />
                    <figcaption align="middle">CBSpheres DAE Rendering</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/part1bench.png" width="480px" />
                    <figcaption align="middle">Bench Rendering</figcaption>
                </td>
            </tr>
            <tr>
                <td align="middle">
                    <img src="images/part1coil.png" width="480px" />
                    <figcaption align="middle">Coil Rendering</figcaption>
                </td>
                </tr>
            </table>
        </div>

        <h2 align="middle">Part 2: Bounding Volume Hierarchy</h2>

        <p>
            To create the Bounding Volume Hierarchy (BVH), I first calculated a bounding box for the collection of primitives and another bounding the centroids of the primitives I used the former to create a new node and the latter for splitting the primitives up. I found the longest axis of this centroid box, took the midpoint, and sorted the primitives based on which side of this point their centroid lands. Then I recursively called this function on each set to make the right and left nodes for the node I created above, with the base case of there being only a small amount of primitives, in which case they are just directly added to the node instead of splitting. 
        </p>
        <p>
            For BVH intersection, I implemented bbox intersection as seen in class and used it as a heuristic for traversing the BVH. If a ray didn't intersect the bounding box of a node, that branch was no longer traversed. If it did however, the branch is traversed and the check repeats itself. This occurs until branches can no longer be traversed, whether due to reaching leaf nodes or having no remaining nodes that have a chance of intersecting the ray. At this point, I run the intersection algorithms for each primitive, allowing the intersection object to store the object first hit by said ray.
        </p>

    <p>
        Performance wise, this is drastically faster than using a single node with all primitives as children. Before it took roughly a minute to render the Cow.dae file on the hive computers with 8 cores. Now I can render the same file on a VM with 2 cores in roughly ten seconds. The centroid approach worked much better than the total bounding box approach/heuristic for BVH generation, as the midpoint had to be recalculated numerous times when all the centroids ended up on one side of the bounding box, and this splitting point dealt with overdampening issues, where it would oscillate on either side of the cluster of primitives but not reach them in a reasonable time. Memory performance could also be improved by changing the recursive algorithms to iterative ones.
    </p>

 <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part2cow.png" width="480px" />
                    <figcaption align="middle">Cow DAE Rendering</figcaption>
                </td>
                    <td align="middle">
                    <img src="images/part2CBbunny.png" width="480px" />
                    <figcaption align="middle">CBBunny Rendering</figcaption>
                </td>
            </tr>
            <tr>
                <td align="middle">
                    <img src="images/part2beetle.png" width="480px" />
                    <figcaption align="middle">Beetle Rendering</figcaption>
                </td>
                <td align="middle">
                    <img src="images/part2CBdragon.png" width="480px" />
                    <figcaption align="middle">CB Dragon Rendering</figcaption>
                </td>
                </tr>
            </table>
        </div>


        <h2 align="middle">Part 3: Direct Illumination</h2>
        <p>
            In this part I implemented two versions of direct lighting, one in which I sampled uniformly on a hemisphere and one in which I only sampled directly from light sources (this function being called "importance"). 
        </p>
        <p>
            Both method are based on the same fundamental idea: we need to integrate over the amount of light hitting an object to calculate the color and amount of light coming from the object. To calculate these integrals, I used Monte Carlo integration, in which I took sample rays, calculated irradiance from them, and took a weighted average (weighted by pdf of sampling function and cosine of the angle of intersection due to Lambert's Law). 
            For the hemisphere method, I sampled uniformly, while in the importance method I sampled only light sources.
        </p>



 <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/task3_hemi_dragon.png" width="480px" />
                    <figcaption align="middle">Dragon rendering with uniform hemisphere sampling</figcaption>
                </td>
                    <td align="middle">
                    <img src="images/task3_imp_dragon.png" width="480px" />
                    <figcaption align="middle">Dragon rendering with important sampling</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task3_hemi_lucy.png" width="480px" />
                    <figcaption align="middle">Lucy rendering with uniform hemisphere sampling</figcaption>
                </td>
                    <td align="middle">
                    <img src="images/task3_imp_lucy.png" width="480px" />
                    <figcaption align="middle">Lucy rendering with important sampling</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task3_hemi_gems.png" width="480px" />
                    <figcaption align="middle">Gems rendering with uniform hemisphere sampling</figcaption>
                </td>
                    <td align="middle">
                    <img src="images/task3_imp_gems.png" width="480px" />
                    <figcaption align="middle">Gems rendering with important sampling</figcaption>
                </td>
            </tr>
            </table>
        </div>



 <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/CBbunny_task3_l1s1.png" width="480px" />
                    <figcaption align="middle">Bunny rendering with 1 light ray</figcaption>
                </td>
                    <td align="middle">
                    <img src="images/CBbunny_task3_l4s1.png" width="480px" />
                    <figcaption align="middle">Bunny rendering with 4 light rays</figcaption>
                </td>
            </tr>
            <tr>
                <td align="middle">
                    <img src="images/CBbunny_task3_l16s1.png" width="480px" />
                    <figcaption align="middle">CBbunny rendering with 16 rays</figcaption>
                </td>
                <td align="middle">
                    <img src="images/CBbunny_task3_l64s1.png" width="480px" />
                    <figcaption align="middle">CBbunny Rendering with 64 rays</figcaption>
                </td>
                </tr>
            </table>
        </div>

        <p>
            While the uniform hemisphere sampling model is more simple, it also has much more noise than the light importance model.
        </p>


        <h2 align="middle">Part 4: Global Illumination</h2>

        <p>
            In part 3, only direct illumination was addressed. However, light does bounce off objects, and as such, we have indirect illumination to take in account as well. In this part, I take this indirect illumination into account and add it to the previously calculated direct illumination.

        </p>

        <p>
            To start for indirect illumination, we take in account emissions from objects. Then we need to account for at least one bounce of light. To take in account every bounce of light, we would have to take an infinite dimensional integral, which isn't easy, so instead I used the Monte Carlo method as in part 3. This time around, I used the max depth variable and a probabilistic coin flip to determine when to stop recursion (AKA integration over time) when determining the light bouncing off an object. Summing the light being emitting, directly bouncing off an object, and indirectly bouncing off an object, I was able to sample the global illumination for the renderings.
        </p>


<p>
    In the only direct light case, all shadows and views not in line with a light source are black. The indirect light case actually has these lit up. Both are also fairly dim compared to the combined rendering.
    </p>
 <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/task4spheres_s1024_dl.png" width="480px" />
                    <figcaption align="middle">Spheres Only Direct Lighting</figcaption>
                </td>
                    <td align="middle">
                    <img src="images/task4spheres_s1024_idl.png" width="480px" />
                    <figcaption align="middle">Spheres Only Indirect Lighting</figcaption>
                </td>
            </tr>

                <tr>
                    <td align="middle">
                    <img src="images/task4spheres_s1024.png" width="480px" />
                    <figcaption align="middle">Spheres Rendering</figcaption>
                </td>
                    <td align="middle">
                    <img src="images/task4dragon.png" width="480px" />
                    <figcaption align="middle">Dragon Rendering</figcaption>
                </td>
            </tr>
            <tr>
                <td align="middle">
                    <img src="images/task4coil.png" width="480px" />
                    <figcaption align="middle">Coil Rendering</figcaption>
                </td>
                <td align="middle">
                    <img src="images/task4lucy.png" width="480px" />
                    <figcaption align="middle">Lucy Rendering</figcaption>
                </td>
                </tr>
            </table>
        </div>

         <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/task4bunny_m0_s1024.png" width="480px" />
                    <figcaption align="middle">Bunny rendering with max depth 0</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4bunny_m1_s1024.png" width="480px" />
                    <figcaption align="middle">Bunny rendering with max depth 1</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4bunny_m2_s1024.png" width="480px" />
                    <figcaption align="middle">Bunny rendering with max depth 2</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4bunny_m3_s1024.png" width="480px" />
                    <figcaption align="middle">Bunny rendering with max depth 3</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4bunny_m100_s1024.png" width="480px" />
                    <figcaption align="middle">Bunny rendering with max depth 100</figcaption>
                </td>
            </tr>
            </table>
        </div>

<p>
    A max depth of 0 would only be light being emitted from objects, so only the above light is visible. A max depth of one is only direct light, so shadows and the ceiling, both not directly being hit by light, are pitch black. For max depths of two and three, we progressively get more light as we take in account more bounces, but as we see with a max depth of 100, this eventually levels off. This comes from our "Russian Roullette" termination probability. I use p = .7, which gives an expected value of 10/7 bounces per ray (< 2).
</p>

         <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/task4spheres_s1.png" width="480px" />
                    <figcaption align="middle">Spheres with 1 sample/pixel</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4spheres_s2.png" width="480px" />
                    <figcaption align="middle">Spheres with 2 samples/pixel</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4spheres_s4.png" width="480px" />
                    <figcaption align="middle">Spheres with 4 samples/pixel</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4spheres_s8.png" width="480px" />
                    <figcaption align="middle">Spheres with 8 samples/pixel</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4spheres_s16.png" width="480px" />
                    <figcaption align="middle">Spheres with 16 samples/pixel</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4spheres_s64.png" width="480px" />
                    <figcaption align="middle">Spheres with 64 samples/pixel</figcaption>
                </td>
            </tr>
            <tr>
                    <td align="middle">
                    <img src="images/task4spheres_s1024.png" width="480px" />
                    <figcaption align="middle">Spheres with 1024 samples/pixel</figcaption>
                </td>
            </tr>
            </table>
        </div>

<p>
    As we increase the number of samples per pixel, we decrease the noise and converge upon the real image (due to the law of large numbers). However, while taking 1024 samples per pixel looks much better than only taking 1, it does take much more computational time.
</p>

 <h2 align="middle">Part 5: Adaptive Sampling</h2>
 <p>
    Adaptive sampling aims to decrease noise from Monte Carlo sampling through statistics. By using confidence intervals, we are able to check whether or not our average pixel value is within +/- MAX_TOLERANCE of out value with a confidence of 95%. At this point, more samples could contribute more noise and lead to a larger interval for the same tolerance, so we stop sampling after this. This reduces the number of pixels we must sample to get a quality rendering. 
 </p>
 <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/task5.png" width="480px" />
                    <figcaption align="middle">Bunny with Max Samples/Pixel</figcaption>
                </td>
                    <td align="middle">
                    <img src="images/task5_rate.png" width="480px" />
                    <figcaption align="middle">Rate for Bunny with Max Samples/Pixel </figcaption>
                </td>
            </tr>
</table>
</div>
       
</div>


<h2 align="middle">Part 6: Mirror and Glass Material</h2>
        <p>Here I implemented bsdf for mirror and glass materials by modeling how light interacts with these materials. By taking in account the reflective and refractive nature of light. Below we can see a rendered image including both materials with different max ray depths. For depth 0, we only see the source lights, and depth one only materials directly in line with the light source are hit, as seen in the prior project. At depth 2, we finally see light reflect off the mirror sphere, and at depth 3, enough light reflects towards the glass sphere that then refracts that we can now see the glass material. At a depth of 4, we can now see the glass ball properly rendered in the reflection of the mirror ball, and at a depth of 5, we can finally see light being reflected from the mirror ball through the glass ball hitting the wall on the right. At further depths like at depth 100 we see values converge and much of the noise disappear.</p>
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/part1_m0.png" width="480px" />
                    <figcaption align="middle">Depth 0</figcaption>
               </td>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/part1_m1.png" width="480px" />
                    <figcaption align="middle">Depth 1</figcaption>
               </td>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/part1_m2.png" width="480px" />
                    <figcaption align="middle">Depth 2</figcaption>
               </td>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/part1_m3.png" width="480px" />
                    <figcaption align="middle">Depth 3</figcaption>
               </td>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/part1_m4.png" width="480px" />
                    <figcaption align="middle">Depth 4</figcaption>
               </td>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/part1_m5.png" width="480px" />
                    <figcaption align="middle">Depth 5</figcaption>
               </td>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/part1_m100.png" width="480px" />
                    <figcaption align="middle">Depth 100</figcaption>
               </td>
                </tr>
            </table>
        </div>


    <h2 align="middle">Part 7: Microfacet Material</h2>
        <p>Here I implemented microfacet modeling using the BRDF evaluation function. By calculating the Fresnel term, shadow-masking term, and normal distribution function, we are able to effectively sample a material. I also implemented importance sampling to speed up rendering and minimize noise. </p>
        <p>
            Below we can see several images rendered with different values of alpha, alpha being the roughness of the surface. We can see how for larger values of alpha, we get much more details in the image. Below that are also images comparing direct sampling with importance sampling for microfacet rendering. The important sampling one has less noise and takes less time than directly sampling.
        </p>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/q2dragon_a005.png" width="480px" />
                    <figcaption align="middle">Alpha = 0.005</figcaption>
               </td>
                    <td align="middle">
                    <img src="images/q2dragon_a05.png" width="480px" />
                    <figcaption align="middle">Alpha = 0.05</figcaption>
               </td>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/q2dragon_a25.png" width="480px" />
                    <figcaption align="middle">Alpha = 0.25</figcaption>
               </td>
                    <td align="middle">
                    <img src="images/q2dragon_a5.png" width="480px" />
                    <figcaption align="middle">Alpha = 0.5</figcaption>
               </td>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/q2bunny_hemi.png" width="480px" />
                    <figcaption align="middle">Direct Sampling</figcaption>
               </td>
                    <td align="middle">
                    <img src="images/q2bunny_imp.png" width="480px" />
                    <figcaption align="middle">Important Sampling</figcaption>
               </td>
                </tr>
</table>
</div>
                <div align="center">
            <table style="width=100%">
            
                <tr>
                    <td align="middle">
                    <img src="images/q2hg_bunny.png" width="480px" />
                    <figcaption align="middle">Mercury Bunny</figcaption>
               </td>
                </tr>
            </table>
        </div>

<h2 align="middle">Part 8: Environment Light Maps</h2>
        <p>In this part, I used environmental light maps as the only light source, probablistically calculating how much light should hit the object of the scene and at what angles, in order to create the appearance that the object actually belonged in the scene.</p>
        <p> The first image below is a visual representation of the conditional and marginal probabilities being calculated for this question. The other images contrast direct sampling and importance sampling for an image and a microfacet image. In general, as can be seen below, importance sampling using probability and our knowledge of the situation in order to sample the most important information first, causing the image to converge to a minimal noise rendering with less samples. This makes important smapling have less noise and render faster than direct sampling given the same number of samples per pixel.
        </p>
        <div align="center">
            <table style="width=100%">
                <tr>
                    <td align="middle">
                    <img src="images/probability_debug.png" width="480px" />
                    <figcaption align="middle">Visual Representation of Probabilities Calculated</figcaption>
               </td>
           </tr>
            </table>
            </div>
           <div align="center">
            <table style="width=100%">            
                 <tr>
                    <td align="middle">
                    <img src="images/q3bunny_dir.png" width="480px" />
                    <figcaption align="middle">Bunny with Direct Sampling</figcaption>
               </td>
                    <td align="middle">
                    <img src="images/q3bunny_imp.png" width="480px" />
                    <figcaption align="middle">Bunny with Important Sampling</figcaption>
               </td>
                </tr>
                <tr>
                    <td align="middle">
                    <img src="images/q3bunny_micro_dir.png" width="480px" />
                    <figcaption align="middle">Microfacet with Direct Sampling</figcaption>
               </td>
                    <td align="middle">
                    <img src="images/q3bunny_micro_imp.png" width="480px" />
                    <figcaption align="middle">Microfacet with Important Sampling</figcaption>
               </td>
                </tr>

            </table>
        </div>

</body>
</html>




